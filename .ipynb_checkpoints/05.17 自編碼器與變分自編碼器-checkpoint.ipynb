{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder and Variational Autoencoder\n",
    "\n",
    "本單元，我們將介紹並帶各位同學實作非監督式學習中的自編碼器及其變形。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 初始準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: keras=Tensorflow\n"
     ]
    }
   ],
   "source": [
    "%env keras=Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interact, FloatSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\w8462\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Input,Lambda\n",
    "from keras.layers import Dense #NN\n",
    "from keras.layers import Conv2D,MaxPooling2D #CNN\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras import metrics\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 讀入 MNIST 數據庫\n",
    "老規矩，開場就先召喚我們的好朋友 - MNIST 手寫數字數據庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train0,y_train0),(x_test0,y_test0)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "調整資料長相及單位化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train0.reshape(60000,-1) #-1為numpy自動計算\n",
    "x_test=x_test0.reshape(10000,-1) #-1為numpy自動計算\n",
    "\n",
    "x_train-=x_train.min()\n",
    "x_train=x_train/x_train.max()\n",
    "\n",
    "x_test-=x_test.min()\n",
    "x_test=x_test/x_test.max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder，又稱為自編碼器，是一個將資料壓縮再還原的模型，通常由一編碼器及一解碼器所組成。\n",
    "\n",
    "給定一組數據集 $\\mathcal{D}\\subseteq\\mathbb{R}^n$ 以及一個壓縮維度 $m$，其中 $m < n$。\n",
    "\n",
    "數學上來說表示，Autoencoder 由 $\\mbox{Enc}:\\mathbb{R}^n\\to\\mathbb{R}^m$ 和 $\\mbox{Dec}:\\mathbb{R}^m\\to\\mathbb{R}^n$ 所構成：\n",
    "\n",
    "$$ \\mathbb{R}^n \\overset{\\mbox{Enc}}{\\to} \\mathbb{R}^m \\overset{\\mbox{Dec}}{\\to} \\mathbb{R}^n$$\n",
    "\n",
    "$$ x \\overset{\\mbox{Enc}}{\\mapsto} h \\overset{\\mbox{Dec}}{\\mapsto} \\hat{x} $$\n",
    "\n",
    "且對於任意的 $x\\in\\mathcal{D}$，我們希望 $x\\approx\\hat{x} = Dec(h) = Dec\\big(Enc(x)\\big)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，$h = \\mbox{Enc}(x)$ 稱之 $x$ 為潛在表示法 (latent representation)，而 $\\hat{x}$ 則是 $x$ 自編碼過後的還原資料。\n",
    "\n",
    "換言之，我們希望原本的資料 $x$，經過函數 $\\mbox{Enc}$ 編碼成維度比較小的資料 $h$，再透過函數 $\\mbox{Dec}$ 還原成 $\\hat{x}$。\n",
    "\n",
    "一般而言，我們會希望 $\\mbox{Enc}$ 和 $\\mbox{Dec}$  看起來有點對稱。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**為了視覺化的目的，經常會考慮 $m=2$ 的狀況。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Autoencoder 與手寫辨識資料 MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們考慮具有下列結構的 Autoencoder:\n",
    "\n",
    "<img src=\"autoencoder.png\" alt=\"drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "為了方便，我們將三個變數的符號表示出來：\n",
    "\n",
    "$$ x \\overset{\\mbox{Enc}}{\\mapsto} h \\overset{\\mbox{Dec}}{\\mapsto} \\hat{x} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_1=Dense(100,activation='sigmoid')\n",
    "enc_2=Dense(2,activation='sigmoid')\n",
    "\n",
    "dec_2=Dense(100,activation='sigmoid')\n",
    "dec_1=Dense(784,activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 202       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               300       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 784)               79184     \n",
      "=================================================================\n",
      "Total params: 158,186\n",
      "Trainable params: 158,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x=Input(shape=(784,))\n",
    "\n",
    "h=enc_2(enc_1(x))\n",
    "\n",
    "x_hat=dec_1(dec_2(h))\n",
    "\n",
    "autoencoder=Model(x,x_hat)\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一樣的，當模型 compile 之後，便可以進行資料的訓練、預測等等，請有興趣的同學讀入 MNIST 手寫辨識之料後，自行完成這個模型的訓練。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(loss='mse',optimizer=Adam(lr=(1e-4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoencoder.fit(x_train,x_train,batch_size=1024,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果覺得訓練太久的話，也可以使用我們準備好的權重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load_weights('autoencoder_handwriting_model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 視覺化 - 子模型的取出\n",
    "為了視覺化(及其他潛在應用)，我們也會從 Autoencoder 將 Encoder 和 Decoder 分別定義出來。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 78,702\n",
      "Trainable params: 78,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Encoder=Model(x,h)\n",
    "Encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder 是由 $h$ 開始，因此，我們先準備一個與 $h$ 相同大小的 `Input`，並餵進 `dec_2` 及 `dec_1` 中即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               300       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 784)               79184     \n",
      "=================================================================\n",
      "Total params: 79,484\n",
      "Trainable params: 79,484\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "h_input=Input(shape=(2,))\n",
    "Decoder=Model(h_input,dec_1(dec_2(h_input)))\n",
    "\n",
    "Decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 視覺化 - Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我們隨便抽取一張圖，並透過 Encoder 來算出它的 latent 表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24474536, 0.11025778]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=5998\n",
    "Encoder.predict(x_train[index:index+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接者，我們從 $10000$ 筆測試資料隨機挑選 $3000$ 手寫辨識資料，將其轉換成 latent 表示法，並畫在同一平面上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds=np.random.randint(10000,size=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent=Encoder.predict(x_train[inds])\n",
    "latent.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40db344b0b7b4281b96c0d0b44e079ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x13194c140b8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(latent[:,0],latent[:,1],c=y_train0[inds],cmap='tab10')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 視覺化 - Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我們在 $[0, 1]\\times[0, 1]$ 這個單位正方形內均勻取樣 $15*15$ 個點，並將這 $225$ 個平面上的點，透過 Decoder 進行圖片的還原。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "grid_x = np.linspace(0.05, 0.95, n)\n",
    "grid_y = np.linspace(0.05, 0.95, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = Decoder.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[(n-i-1) * digit_size: (n - i) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10ca21262c4414ebd56d5cc86db122a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='Greys')\n",
    "#plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Variational Autoencoder\n",
    "若每筆資料的 latent 不僅僅是一個**位置**，而是一個分布，且分布的平均值附近都能還原，那我們應該怎麼做呢？\n",
    "\n",
    "在此，我們將介紹 Variational Autoencder，一種當代知名的自編碼器，就具有上述的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此時 $\\mbox{Enc}$ 和 $\\mbox{Dec}$ 並不直接串接，而是會透過一常態抽樣的函數以下面的形式串接。\n",
    "\n",
    "$$ \\mathbb{R}^n \\overset{\\mbox{Enc}}{\\to} \\mathbb{R}^m\\times\\mathbb{R}^m \\overset{\\mbox{Sampling}}{\\to} \\mathbb{R}^m \\overset{\\mbox{Dec}}{\\to} \\mathbb{R}^n$$\n",
    "\n",
    "$$ x \\overset{\\mbox{Enc}}{\\mapsto} (\\mu, \\sigma^2) \\overset{\\mbox{Sampling}}{\\mapsto} h \\overset{\\mbox{Dec}}{\\mapsto} \\hat{x} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們準備建構的 Variational Autoencoder 的結構如下：\n",
    "\n",
    "<img src=\"variational_autoencoder.png\" alt=\"drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在此， Encoder 的作用不是將資料表示成 latent，而是將資料表示成常態分配的兩個參數，平均數與變異數。\n",
    "\n",
    "而 Decoder 也不再直接使用 Encoder 的結果，而是將 Encoder 的結果作為常態抽樣的兩個參數來進行。\n",
    "\n",
    "因此，資料經過 Encoder，會得到一適當大小的常態分配之參數，而 Decoder 則使用這組參數進行抽樣。\n",
    "\n",
    "即使是同一筆資料，Decoder 每次接受到的 latent 表示法可能都不一樣 (但會在某個平均數附近)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要注意到的是，由於變異數恆正的特性，我們可以下面是以學習取對數後的變異數 (log-variance)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 VAE 的建立\n",
    "為了避免混淆，我們重新定義所有變數，首先，我們定義 Encoder 上的三個神經網路層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_1=Dense(100,activation='sigmoid')\n",
    "\n",
    "enc_mean=Dense(2)\n",
    "enc_log_var=Dense(2)\n",
    "\n",
    "dec_2=Dense(100,activation='sigmoid')\n",
    "dec_1=Dense(784,activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=Input(shape=(784,))\n",
    "\n",
    "enc_x=enc_1(x)\n",
    "\n",
    "z_mean=enc_mean(enc_x)\n",
    "z_log_var=enc_log_var(enc_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定義抽樣函數並透過 ``Lambda`` 將其轉換成 Keras layer。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "透過 $X\\sim N(0, 1)\\Rightarrow \\mu+\\sigma X\\sim N(\\mu, \\sigma^2)$ 和 $\\sigma = e^{\\frac{\\log{\\sigma^2}}{2}}$，我們透過以下方式定義抽樣函數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean,z_log_var=args\n",
    "    epsilon=k.random_normal(shape=(2,),mean=0,stddev=1) #X∼N(0,1)\n",
    "    return z_mean+k.exp(z_log_var/2)*epsilon\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=Lambda(sampling,output_shape=(2,))([z_mean,z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hat=dec_1(dec_2(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 100)          78500       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            202         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2)            202         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2)            0           dense_6[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 100)          300         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 784)          79184       dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 158,388\n",
      "Trainable params: 158,388\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "VAE=Model(x,x_hat)\n",
    "VAE.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Loss 函數的建立\n",
    "VAE 的 loss 函數，其由來牽扯一些訊息理論 (information theory) 的知識，因此，我們在此直接建立訓練 VAE 時的 loss 函數。\n",
    "\n",
    "若對 VAE 的理論及模型基本設定有興趣的同學，可以參考下列兩篇論文：\n",
    "* Auto-Encoding Variational Bayes: https://arxiv.org/pdf/1312.6114.pdf\n",
    "* Tutorial on Variational Autoencoders: https://arxiv.org/pdf/1606.05908.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同學有興趣可以證明下面關於 KL 散度在兩個常態分配上的性質：若 $p\\sim N(\\mu_1,\\sigma_1^2)$, $q\\sim N(\\mu_2,\\sigma_2^2)$，則 $KL(p, q) = \\log\\dfrac{\\sigma_2}{\\sigma_1} + \\dfrac{\\sigma_1^2+(\\mu_1-\\mu_2)^2}{2\\sigma_2^2}-\\dfrac{1}{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(x,x_recon):\n",
    "    recovery_loss=784*metrics.binary_crossentropy(x,x_recon)\n",
    "    KL_loss=-0.5*k.sum(1+z_log_var-k.square(z_mean)-k.exp(z_log_var),axis=-1)\n",
    "    return recovery_loss+KL_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 訓練 VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE.compile(loss=vae_loss,optimizer=Adam(lr=1e-04))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAE.fit(x_train,x_train,batch_size=1024,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE.load_weights('VAE_handwriting_model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 VAE 的視覺化呈現\n",
    "與視覺化 Autoencoder 時的方式一樣，我們先分別定義出 Encoder 和 Decoder。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mbox{VAE:}~x \\overset{\\mbox{Enc}}{\\mapsto} (\\mu, \\sigma^2) \\overset{\\mbox{Sampling}}{\\mapsto} h \\overset{\\mbox{Dec}}{\\mapsto} \\hat{x} $$\n",
    "$$\\mbox{Encoder:}~x \\overset{\\mbox{Enc}}{\\mapsto} \\mu$$\n",
    "$$\\mbox{Decoder:}~h \\overset{\\mbox{Dec}}{\\mapsto} \\hat{x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 78,702\n",
      "Trainable params: 78,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "VAE_encoder=Model(x,z_mean)\n",
    "VAE_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               300       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 784)               79184     \n",
      "=================================================================\n",
      "Total params: 79,484\n",
      "Trainable params: 79,484\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "VAE_decoder=Model(h_input,dec_1(dec_2(h_input)))\n",
    "VAE_decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我們進行 Encoder 的視覺化呈現。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAE_latent=VAE_encoder.predict(x_train[inds])\n",
    "VAE_latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x131990248d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(VAE_latent[:,0],VAE_latent[:,1],c=y_train0[inds],cmap='tab10')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized(x):\n",
    "    x-=x.min()\n",
    "    x/=x.max()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著，我們進行 Decoder 的視覺化呈現。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_x_vae = np.linspace(-4+0.05, 4-0.05, n)\n",
    "grid_y_vae = np.linspace(-4+0.05, 4-0.05, n)\n",
    "VAE_figure = np.zeros((digit_size * n, digit_size * n))\n",
    "for i, yi in enumerate(grid_x_vae):\n",
    "    for j, xi in enumerate(grid_y_vae):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = VAE_decoder.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        VAE_figure[(n-i-1) * digit_size: (n - i) * digit_size,\n",
    "                   j * digit_size: (j + 1) * digit_size] = normalized(digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d9f36c544d497b8156c151f5fc91d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(VAE_figure,cmap='Greys')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 與 Autoencoder 的 Encoder 進行視覺化比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 動態比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inBetween(t):\n",
    "    data_0 = x_train0[idx_1]\n",
    "    data_1 = x_train0[idx_2]\n",
    "    data_t = (1-t)*x_train0[idx_1] + t*x_train0[idx_2]\n",
    "\n",
    "    mu_0 = VAE_encoder.predict(x_train[idx_1:idx_1+1]).squeeze()\n",
    "    mu_1 = VAE_encoder.predict(x_train[idx_2:idx_2+1]).squeeze()\n",
    "    mu_t = (1-t)*mu_0 + t*mu_1\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    ax1 = plt.subplot(2, 1, 2)\n",
    "    ax1.scatter(mu_0[0], mu_0[1])\n",
    "    ax1.scatter(mu_1[0], mu_1[1])\n",
    "    ax1.scatter(mu_t[0], mu_t[1])\n",
    "\n",
    "    ax2 = plt.subplot(2, 3, 1)\n",
    "    ax2.imshow(data_0, cmap='Greys')\n",
    "\n",
    "    ax3 = plt.subplot(2, 3, 2)\n",
    "    ax3.imshow(data_t, cmap='Greys')\n",
    "\n",
    "    ax4 = plt.subplot(2, 3, 3)\n",
    "    ax4.imshow(data_1, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b4fe35ed244adfb403aaad6d530685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='t', max=1.0, step=0.02), Output()), _dom_classes=('w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.inBetween(t)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_1, idx_2 = np.random.randint(x_test.shape[0], size=2)\n",
    "interact(inBetween, t=FloatSlider(value=0.5,min=0,max=1.0,step=0.02,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
