{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用各種不同方式寫同樣的神經網路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 初始準備\n",
    "\n",
    "Keras 可以用各種不同的深度學習套件當底層, 我們在此指定用 Tensorflow 以確保執行的一致性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND = tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from ipywidgets import interact,IntSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讀入建構神經網路用到的 Keras 相關函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\w8462\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Activation\n",
    "from keras.optimizers import SGD,Adam\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 讀入 MNIST 數據庫\n",
    "\n",
    "MNIST 是有一堆 0-9 的手寫數字圖庫。有 6 萬筆訓練資料, 1 萬筆測試資料。它是 \"Modified\" 版的 NIST 數據庫, 原來的版本有更多資料。這個 Modified 的版本是由 LeCun, Cortes, 及 Burges 等人做的。可以參考這個數據庫的[原始網頁](http://yann.lecun.com/exdb/mnist/)。\n",
    "\n",
    "MNIST 可以說是 Deep Learning 最有名的範例, 它被 Deep Learning 大師 Hinton 稱為「機器學習的果蠅」。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 由 Keras 讀入 MNIST\n",
    "標準手段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train0,y_train0),(x_test0,y_test0)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "養成好習慣，沒事就看看資料的長相"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共 60000 訓練資料，每筆資料尺寸為 28 X 28\n"
     ]
    }
   ],
   "source": [
    "print('共 %d 訓練資料，每筆資料尺寸為 %d X %d'%x_train0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 輸入格式整理\n",
    "\n",
    "我們現在要用標準神經網路學學手寫辨識。原來的每筆數據是個 28x28 的矩陣 (array), 但標準神經網路只吃「平平的」, 也就是每次要 28x28=784 長的向量。因此我們要用 `reshape` 調校一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train0.reshape((60000,28*28))\n",
    "x_test=x_test0.reshape((10000,28*28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將資料線性單位化至 $[0, 1]$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train-=x_train.min()\n",
    "x_train=x_train/x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train.min(),x_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test-=x_test.min()\n",
    "x_test=x_test/x_test.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們來準備另一個 label，將 0~9 分成偶數(y=0)、奇數 (y=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_num=to_categorical(y_train0,10)\n",
    "y_test_num=to_categorical(y_test0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_eo=np.ones_like(y_train0)\n",
    "y_train_eo[y_train0%2==0]=0\n",
    "\n",
    "y_test_eo=np.ones_like(y_test0)\n",
    "y_test_eo[y_test0%2==0]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "沒事用互動模式畫個圖，十分酷炫 (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 回顧 Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在第一周的時候，我們以下列的方式建立了一個具有下列設定\n",
    "\n",
    "* 使用 <span style=\"color:red;\">2</span> 個 hidden layers\n",
    "* 每個 hidden layer 用 <span style=\"color:red;\">500</span> 個神經用\n",
    "* Activation Function 唯一指名 <span style=\"color:red;\">sigmoid</span> (雖然好像有些同學測試出 <span style=\"color:red;\"> ReLU </span> 比較好用...)\n",
    "* 最後一層為類別層，有 **10** 個神經元，Activation Function 為 ``softmax``。\n",
    "\n",
    "的神經網路，建立指令是透過建立 `Sequential()` 和 `.add` 的方式逐層建立，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 648,010\n",
      "Trainable params: 648,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model =Sequential()\n",
    "\n",
    "model.add(Dense(500,input_dim=28*28))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 另一種使用 Sequential 建立神經網路的方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "觀察 ''model.layers``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0x1f891414c18>,\n",
       " <keras.layers.core.Activation at 0x1f891414eb8>,\n",
       " <keras.layers.core.Dense at 0x1f8914263c8>,\n",
       " <keras.layers.core.Activation at 0x1f891426e48>,\n",
       " <keras.layers.core.Dense at 0x1f89144d470>,\n",
       " <keras.layers.core.Activation at 0x1f89144d7f0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以發現 `model` 就是一堆神經網路***層*** 堆疊起來。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Python\n",
    "# 建立空的神經網路學習機\n",
    "model = Sequential()\n",
    "\n",
    "# 逐層建立神經網路 \n",
    "model.add(Dense(500, input_dim=784)) # 將 `<keras.layers.core.Activation at 0xe558ef0>` 加進 model.layers\n",
    "model.add(Activation('sigmoid'))     # 將 `<keras.layers.core.Dense at 0xe58a278>` 加入 model.layers\n",
    "model.add(Dense(500))                # 將 `<keras.layers.core.Dense at 0xe58a278>` 加入 model.layers\n",
    "model.add(Activation('sigmoid'))     # 將 `<keras.layers.core.Activation at 0xe558d68>` 加入 model.layers\n",
    "model.add(Dense(10))                 # 將 `<keras.layers.core.Activation at 0xe558d68>` 加入 model.layers\n",
    "model.add(Activation('softmax'))     # 將 `<keras.layers.core.Activation at 0xe58a898>` 加入 model.layers\n",
    "\n",
    "model.summary()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "換言之，神經網路其實就是將隱藏層逐層堆疊在一起的 list，因此，我們也可以 list 的形式來建立相同的神經網路。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我們將兩個隱藏層及其 Activation Function 分別寫在 list 中，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer=[Dense(500,input_dim=28*28),Activation('sigmoid')]\n",
    "second_layer=[Dense(500),Activation('sigmoid')]\n",
    "final_layer=[Dense(10),Activation('softmax')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從基本的 Python 資料結構中，我們知道 list 可以用 `+` 來進行合併，所以我們先來看看這三個 list 合併後的樣子。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "modle=Sequential(first_layer+second_layer+final_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合併起來的 list 看起來就像是某個 `model.layers` 一樣，因此，我們只需將這些寫成 list 的隱藏層 `+` 起來送進 `Sequential` 中即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 648,010\n",
      "Trainable params: 648,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: 用 `.add` 和用 list 寫法建立的神經網路之差異？\n",
    "\n",
    "### A: 沒有任何差別，前者可以很直覺得將神經網路堆疊起來，但後者則是轉移學習 (Transfer Learning) 的方式之一。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 站在巨人的肩膀上 - 轉移學習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "舉例來說，如果我們今天想進行的辨識資料從辨識數字 (0~9) 變成了辨識奇偶數 (0 or 1)，而且我們希望延用之前***除了最後一層***的模型。\n",
    "\n",
    "顯然地，目前神經網路的 output 就與我們的需求不同，但我們想把前兩個隱藏層原封不動，只定義***新的最後一層***。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 648,010\n",
      "Trainable params: 648,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "all_except_last_layer=[Dense(500,input_dim=28*28),\n",
    "                       Activation('sigmoid'),\n",
    "                       Dense(500),\n",
    "                       Activation('sigmoid')]\n",
    "\n",
    "last_layer=[Dense(10),Activation('softmax')]\n",
    "\n",
    "model_num=Sequential(all_except_last_layer+last_layer)\n",
    "\n",
    "model_num.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讀取個權重，記得要先 ``compile``，才能 ``fit``, ``evaluate``, ``predict``, ``predict_classes``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "舉例來說，如果我們今天想進行的辨識資料從辨識數字 (0~9) 變成了辨識奇偶數 (0 or 1)，而且我們希望延用之前***除了最後一層***的模型。\n",
    "\n",
    "顯然地，目前神經網路的 output 就與我們的需求不同，但我們想把前兩個隱藏層原封不動，只定義***新的最後一層***。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num.load_weights('handwriting_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 11us/step\n"
     ]
    }
   ],
   "source": [
    "score=model_num.evaluate(x_train,y_train_num,batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4705149233341217, 0.8622666597366333]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "但這個網路並不是重點，我們只希望***借用***某些部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們希望**借用**這個模型的某些部分。來建立 **奇、偶數辨識模型**，模型設定如下：\n",
    "\n",
    "* 使用 <span style=\"color:red;\">2</span> 個 hidden layers\n",
    "* 每個 hidden layer 用 <span style=\"color:red;\">500</span> 個神經元\n",
    "* Activation Function 唯一指名 <span style=\"color:red;\">sigmoid</span> (雖然好像有些同學測試出 <span style=\"color:red;\"> ReLU </span> 比較好用...)\n",
    "* 最後一層為類別層，有 ~~10~~ **<span style=\"color:red;\">2</span>** 個神經元，Activation Function 為 ``softmax``。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer_eo=[Dense(2),Activation('softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 1002      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 644,002\n",
      "Trainable params: 644,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_eo=Sequential(all_except_last_layer+last_layer_eo)\n",
    "model_eo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "什麼都不做，就直接 ``evaluate``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eo.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_eo=to_categorical(y_train_eo,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 9us/step\n"
     ]
    }
   ],
   "source": [
    "score=model_eo.evaluate(x_train,y_train_eo,batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8133865892887115, 0.4915333290894826]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練過後再看一次："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.3699 - acc: 0.8456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f8aef8f710>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eo.fit(x_train,y_train_eo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們再回頭看看原本模型發生什麼事情"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 33us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46726733455260594, 0.8658166666666667]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_num.evaluate(x_train,y_train_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果希望借來的模型權重，在訓練過程中不要改變，該如何做？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_except_last_layer[0].trainable==False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in all_except_last_layer:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_except_last_layer[3].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 1002      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 644,002\n",
      "Trainable params: 1,002\n",
      "Non-trainable params: 643,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_eo.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['acc'])\n",
    "model_eo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 重新讀取**舊**模型權重 (並 evaluate)\n",
    "2. 定義新模型並凍結**舊**模型的部分\n",
    "3. 訓練新模型\n",
    "4. 回頭看就模型的evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num.load_weights('handwriting_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eo=Sequential(all_except_last_layer+last_layer_eo)\n",
    "model_eo.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.3472 - acc: 0.8499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f996bc4fd0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eo.fit(x_train,y_train_eo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 0s 7us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4705149233341217, 0.8622666597366333]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_num.evaluate(x_train,y_train_num,batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 恭喜！現在的你/妳已經學會實作轉移學習了！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "雖然這個模型看起來很隨便，但轉移學習的模型**差不多**都是這樣建立的，實際上， Keras 亦提供許多被證實有良好表現且訓練好 (pre-trained) 的模型，如:\n",
    "\n",
    "* Xception\n",
    "* VGG16\n",
    "* VGG19\n",
    "* ResNet50\n",
    "* InceptionV3\n",
    "* InceptionResNetV2\n",
    "* MobileNet\n",
    "* DenseNet\n",
    "* NASNet\n",
    "\n",
    "詳細的使用方式可參考 Keras Documentation: https://keras.io/applications/\n",
    "\n",
    "但使用這些模型進行轉移學習，**可能**需要 ``Sequential`` 以外寫法，以及更多神經網路的建構技巧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 寫起來像寫數學函數的 Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在此之前，我們使用 Sequential 便足以建構大多數的神經網路，那是因為我們接觸的神經網路多為線性堆疊 (linear stack)。\n",
    "\n",
    "除了輸入層需指定 `input_dim` 外，其餘隱藏層只需宣告，那是因為 Sequential 會認定上一層的輸出這一層的輸入。\n",
    "\n",
    "因此，再建構線性堆疊的神經網路時，Sequential 便足以處理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Functional API 的使用時機"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "當神經網路模型為非線性的複雜網路結構，如：\n",
    "\n",
    "* 多重輸出-多重輸入模型 (Multi-input and multi-output models)\n",
    "  + 分歧 (branch)\n",
    "  + 合併 (merge)\n",
    "* 具重複/循環結構的模型，如: CycleGAN\n",
    "\n",
    "Sequential 便不足以建構這類複雜結構的神經網路，我們以下介紹 `Model` Fnuctional API 的使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 `Model` 的世界中，所有的神經網路層 (全連接, 卷積, 池化, RNN等) 都將視作函數來定義，因此，我們只需關心函數的輸入和輸出即可。\n",
    "\n",
    "此外，為了讓神經網路的第一層從不需要輸入 `input_dim`，我們還需引進下面這個函數來代替 `input_dim`。 (此寫法亦可用在 `Sequential`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Functional API 的函數概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回顧一下，我們想學習的手寫辨識模型是一個長得像這樣的函數\n",
    "\n",
    "$$\\hat{f} \\colon \\mathbb{R}^{784} \\to \\mathbb{R}^{10}$$\n",
    "\n",
    "我們希望建立一個具有兩個隱藏層的神經網路來學習這個函數，攤開來看的話，如下：\n",
    "\n",
    "$$\\mathbb{R}^{784} \\overset{f_1}{\\to} \\mathbb{R}^{500} \\overset{f_2}{\\to} \\mathbb{R}^{500} \\overset{f_3}{\\to} \\mathbb{R}^{10}$$\n",
    "\n",
    "$$x \\overset{f_1}{\\mapsto} h_1 \\overset{f_2}{\\mapsto} h_2 \\overset{f_3}{\\mapsto} y$$\n",
    "\n",
    "\n",
    "或是以簡易的圖來表示這個全連接神經網路\n",
    "\n",
    "<img src=\"plain_model.png\" alt=\"drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "其中，$f_1, f_2, f_3$ 代表的是全連結層所代表的函數，其他變數說明如下：\n",
    "\n",
    "* $x$: 代表的是輸入模型的圖片向量，為 784 維的向量。\n",
    "* $h_1$: $x$ 經過第一層隱藏層運算後得結果，即為 $f_1(x)$，為 500 維的向量。\n",
    "* $h_2$: $h_1$ 經過第二層隱藏層運算後得結果，即為 $f_2(h_1)$，為 500 維的向量。\n",
    "* $y$: $h_2$ 經過最後一層運算後得結果，即為 $f_3(h_2)$，為 10 維的向量，代表的是 $x$ 為哪個數字的機率。\n",
    "\n",
    "注意: 為了方便，我們將 `Dense(500)`, `Activation('sigmoid')` 兩個合併用 `Dense(500, activation='sigmoid')` 表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Functional API 的操作方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們沿用上圖的變數名稱來定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=Input(shape=(784,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_1=Dense(500,activation='sigmoid')\n",
    "f_2=Dense(500,activation='sigmoid')\n",
    "f_3=Dense(10,activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著，定義層前後變數之間的關係；首先，第一個變數必定以 `Input` 函數來定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_1=f_1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1:0\", shape=(?, 784), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_11/Sigmoid:0\", shape=(?, 500), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(h_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.Dense object at 0x000001F997E1ED68>\n"
     ]
    }
   ],
   "source": [
    "print(f_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "剩下的部分，就如變數說明，**幾乎**可以照著數學式輸入 $$h_1 = f_1(x), h_2 = f_2(h_1), y = f_3(h_2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_2=f_2(h_1)\n",
    "y=f_3(h_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在這裡，變數 $h_1, h_2, y$ 是以張量 (tensor) 類別來表示，我們可以嘗試 `print` 看看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著，透過 `Model` 將一個模型的輸入/輸出包裝起來，建立模型的過程就完成了！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 648,010\n",
      "Trainable params: 648,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Model(x,y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一樣的，當模型 compile 之後，便可以進行資料的訓練、預測等等，請有興趣的同學讀入 MNIST 手寫辨識之料後，自行完成這個模型的訓練。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=SGD(lr=0.1), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x_train, y_train, batch_size=100, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "雖然 summary 少了很多東西，但模型架構和之前做的沒有差異，所以可以安心讀入之前訓練好的權重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('handwriting_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 11us/step\n",
      "Loss: 0.021306\n",
      "準確率: 86.226666\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_train, y_train_num, batch_size=10000)\n",
    "print(\"Loss: %f\" %score[0])\n",
    "print(\"準確率: %f\" %(score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 小結論\n",
    "Functional API 的操作流程如下：\n",
    "1. 將層定義成明確的函數\n",
    "2. 透過層函數將變數連接\n",
    "3. 定義神經網路的輸入與輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 非線性堆疊模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 如果建立具分歧及合併結構的神經網路模型呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate,add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，假設我們希望在模型之間增加一個分歧，且這個分歧在模型的輸出會合併，則神經網路的結構會變成：\n",
    "\n",
    "<img src=\"branch-and-merge.png\" alt=\"drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "此模型為單一輸入、多重輸出的模型，是分歧模型最容易處理的一種。\n",
    "\n",
    "其中，$f_1, f_2$ 同之前，$f_4:\\mathbb{R}^{500}\\to\\mathbb{R}^{500}$ 的全連接層，但 `Activation` 改用 `ReLu`。\n",
    "\n",
    "需注意的是，由於 $f_3$ 的定義域改變，為 $\\mathbb{R}^{500}\\times\\mathbb{R}^{500}\\to\\mathbb{R}^{10}$ 函數，所以需要重新定義。\n",
    "\n",
    "* $x$: 代表的是輸入模型的圖片向量，為 784 維的向量。\n",
    "* $h_1$: $x$ 經過 $f_1$ 隱藏層運算後得結果，即為 $f_1(x)$，為 500 維的向量。\n",
    "* $h_2$: $h_1$ 經過 $f_2$ 隱藏層運算後得結果，即為 $f_2(h_1)$，為 500 維的向量。\n",
    "\n",
    "* $z$: $h_1$ 經過 $f_4$ 運算後得結果，即為 $f_4(h_1)$，為 500 維的向量。\n",
    "* $y$: $h_2$ 和 $z$ 經過新的 $f_3$ 運算後得結果，即為 $f_3(h_1, z)$，為 10 維的向量，代表的是 $x$ 為哪個數字的機率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因為上面已將 $f_4$ 及 $z$ 以外的變數定義好，我們只需定義 $f_3$, $f_4$ 及 $z$ 即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_3=Dense(10,activation='softmax')\n",
    "f_4=Dense(500,activation='relu')\n",
    "\n",
    "z=f_4(h_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著，再將 $y = f_3(h_2, z)$ 定義好，就會發現......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-8d0130cf7ec7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 此段程式碼為錯誤範例\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __call__() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# 此段程式碼為錯誤範例\n",
    "y=f_3(h_2,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "聰明的你/妳，可能會想到，函數的寫法是一次送進一個變數，那我們將 $h_3$ 和 $z$ 寫成 `list` 的形式，應該就可以送進去 $f_3$ 了吧？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer dense_16 expects 1 inputs, but it received 2 input tensors. Input received: [<tf.Tensor 'dense_12/Sigmoid:0' shape=(?, 500) dtype=float32>, <tf.Tensor 'dense_17/Relu:0' shape=(?, 500) dtype=float32>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-2d055017153e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 此段程式碼為錯誤範例\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mh_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    412\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    297\u001b[0m                              \u001b[1;34m'but it received '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m                              \u001b[1;34m' input tensors. Input received: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m                              str(inputs))\n\u001b[0m\u001b[0;32m    300\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0minput_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Layer dense_16 expects 1 inputs, but it received 2 input tensors. Input received: [<tf.Tensor 'dense_12/Sigmoid:0' shape=(?, 500) dtype=float32>, <tf.Tensor 'dense_17/Relu:0' shape=(?, 500) dtype=float32>]"
     ]
    }
   ],
   "source": [
    "# 此段程式碼為錯誤範例\n",
    "y=f_3([h_2,z])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "會發現這樣也沒辦法成功。其實正確的作法是，先將 $h_2$ 與 $z$ 透過 `concatenate` 接在一起，再送進新的 $f_3$ 裡。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在這裡，我們將 $h_2$ 與 $z$ `concatenate` 接在一起，稱做 $u$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "u=concatenate([h_2,z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=f_3(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "換句話說，模型其實是這樣畫的\n",
    "\n",
    "<img src=\"branch-and-merge_final.png\" alt=\"drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "其中，`concatenate` 是將不同的變數**接**在一起，這裡面並沒有進行任何涉及權重的運算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再透過 `Model` 將模型的輸入和輸出包裝起來，即可將模型建構完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 500)          392500      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 500)          250500      dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 500)          250500      dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1000)         0           dense_12[0][0]                   \n",
      "                                                                 dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 10)           10010       concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 903,510\n",
      "Trainable params: 903,510\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Model(x,y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 小結論\n",
    "Branch-and-Merge 的注意要點如下：\n",
    "1. 每一層分別定義成函數\n",
    "2. 分歧結構: 實就是透過新的函數來定義新的變數，無特別注意事項。\n",
    "3. 合併結構: 要合併前，將所有要進入的變數都合併起來，才能進行之後的運算。\n",
    "\n",
    "常見應用:\n",
    "1. 多重輸入-多重輸出模型。\n",
    "2. 當層函數為 convolution 時，這樣的技巧可以實現 U-net 上的重要結構 multi-resolution fusion (多解析度融合，又稱 MRF)。\n",
    "3. ResNet 上的重要結構 skip connection (跳躍式傳遞)，亦可透過分歧-合併來實現，只是 ResNet 使用的是 `add` 而非 `concatenate`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 自定義的不具可訓練權重之神經網路層\n",
    "這裡，我們將進行這單元最後一個重要的神經網路建構技巧 - 自定義神經網路層 (不具可訓練權重)\n",
    "\n",
    "** 具有可訓練重的自定義層牽扯到 TensorFlow 及 Python 類別的撰寫，若有興趣可參考: https://keras.io/layers/writing-your-own-keras-layers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我們需要引入 `Lambda` 這個函數，透過 `Lambda` 函數，我們可以將 Python 上的 function，包裝成 Keras 上的 layer。\n",
    "\n",
    "此外，我們需要引進後端所使用的套件 (此處為 TensorFlow)，並使用裡面的運算進行 function 的撰寫。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我們透過 backend 來定義一個簡單的 function，作用是對輸入取平均，程式碼如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著，我們將一個 numpy array 送進這個函式，看看會發生什麼事。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.dtype' object has no attribute 'base_dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-964049467819>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 此段程式碼為錯誤範例\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtest_array\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(x, axis, keepdims)\u001b[0m\n\u001b[0;32m   1394\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmean\u001b[0m \u001b[0mof\u001b[0m \u001b[0melements\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1395\u001b[0m     \"\"\"\n\u001b[1;32m-> 1396\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1397\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1398\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.dtype' object has no attribute 'base_dtype'"
     ]
    }
   ],
   "source": [
    "# 此段程式碼為錯誤範例\n",
    "test_array=np.arange(12).reshape(1,2,6)\n",
    "K.mean(test_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你/妳會發現，這邊的函式不接受 numpy array 的類型作為輸入，這是因為 TensorFlow 有自定義的類型，因此，在這邊我們沒辦法直接使用這個函式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Output tensors to a Model must be the output of a Keras `Layer` (thus holding past layer metadata). Found: Tensor(\"Mean_2:0\", shape=(), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-76f3a5315f07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[0;32m     92\u001b[0m             \u001b[1;31m# Graph network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[1;31m# Subclassed network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[1;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[0;32m    186\u001b[0m                                  \u001b[1;34m'the output of a Keras `Layer` '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                                  \u001b[1;34m'(thus holding past layer metadata). '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m                                  'Found: ' + str(x))\n\u001b[0m\u001b[0;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_base_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         self._compute_previous_mask = (\n",
      "\u001b[1;31mValueError\u001b[0m: Output tensors to a Model must be the output of a Keras `Layer` (thus holding past layer metadata). Found: Tensor(\"Mean_2:0\", shape=(), dtype=float32)"
     ]
    }
   ],
   "source": [
    "y=K.mean(x)\n",
    "model=Model(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們透過 `Lambda` ，將上述函式包裝成一個神經網路層。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_mean=Lambda(K.mean,output_shape=(5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'lambda_4/Mean:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_mean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(x,keras_mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "lambda_4 (Lambda)            (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此時，下述程式碼可以建構出一個將指定長度的資料取平均的神經網路。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13768007], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13768007202881152"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0:1].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以發現，這樣的神經網路是不具有訓練權重的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "記得，在使用前記得先 compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著，我們將 `[1, 2, 3, 4]` 送進這個神經網路，看看神經網路的輸出是否為這個向量的**平均。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以發現，將 `[1, 2, 3, 4]` 轉成 Numpy array 送進神經網路**預測**後，答案是 `2.5`，即為 (1+2+3+4)/4，確實是平均。\n",
    "\n",
    "我們也可以一次送進多筆資料進行平均的計算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加碼: 具抽樣功能的神經網路層\n",
    "\n",
    "輸入為 $(\\mu, s)$ ，$\\mu=(\\mu_1,\\cdots,\\mu_n)$ 和 $s=(s_1,\\cdots,s_n)$ 各自為 $n$ 維向量。\n",
    "\n",
    "我們希望神經網路層輸出為服從 $N(\\mu, e^{s}I_n)$ 的 $n$ 維向量，換言之，我們希望建構的神經網路其實是一個抽樣函數。\n",
    "\n",
    "** 由於神經網路的輸入輸出經常沒有限制，為了讓 $s$ 具有變異數的非負特性，我們考慮 $e^{s}$ 作為變異數；換言之，$s$ 為 log-variance。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假設我們想進行抽樣的維度為 `sampling_dim`，則一個具抽樣函數功能的神經網路可由下述方式建構。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_dim=2\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(sampling_dim,), mean=0., stddev=1)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這裡使用到常態分配的線性特性來定義函數，亦即\n",
    "\n",
    "$$X\\sim N(0, 1)\\Rightarrow \\mu+\\sigma X\\sim N(\\mu, \\sigma^2)$$\n",
    "\n",
    "\n",
    "若不熟機率論的同學，可以詢問助教。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_layer=Lambda(sampling,output_shape=(sampling_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=Input(shape=(sampling_dim,))\n",
    "log_s=Input(shape=(sampling_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=sample_layer([m,log_s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\w8462\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"la...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "sampling_model=Model(input=[m,log_s],output=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 2)            0           input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sampling_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "透過下面的指令，我們每次可以抽樣出一服從上述要求常態分配之隨機向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.8339381, 1.2206626]], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_model.predict([[[4.,2.]],[[0.,0.]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "來和 Numpy 上的抽樣函數進行比較吧~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np_sampling=np.random.multivariate_normal([4.,2.],np.identity(2),size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_sampling = np.zeros((100,2))\n",
    "\n",
    "for i in range(100):\n",
    "    keras_sampling[i] = sampling_model.predict([[[4.,2.]],[[0.,0.]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.68292856,  2.54613066],\n",
       "       [ 4.98414373,  1.73676264],\n",
       "       [ 2.23056698,  3.08676887],\n",
       "       [ 3.15441179,  3.12844849],\n",
       "       [ 4.96794033,  3.04521656],\n",
       "       [ 2.99856687,  1.34839678],\n",
       "       [ 2.95140409,  3.52775645],\n",
       "       [ 5.14469719,  1.30051696],\n",
       "       [ 5.91270781,  0.93190944],\n",
       "       [ 2.65565062,  2.7125144 ],\n",
       "       [ 3.98483348,  2.85906458],\n",
       "       [ 4.44659662,  1.77331531],\n",
       "       [ 6.03554916,  1.47289681],\n",
       "       [ 3.31435299,  0.58975995],\n",
       "       [ 2.96936226,  2.79464483],\n",
       "       [ 3.27915955,  3.08230495],\n",
       "       [ 4.65768003,  2.11808658],\n",
       "       [ 5.69616461,  3.82648468],\n",
       "       [ 3.99084783,  2.09306812],\n",
       "       [ 4.04108953,  1.20826101],\n",
       "       [ 5.48215151,  3.03447676],\n",
       "       [ 3.11104989,  2.37038398],\n",
       "       [ 5.07081127,  1.67368269],\n",
       "       [ 3.52594209,  2.78188848],\n",
       "       [ 4.67748928,  1.64330208],\n",
       "       [ 3.55640864,  2.44947147],\n",
       "       [ 3.1495924 ,  3.60712242],\n",
       "       [ 3.62737632,  1.07746887],\n",
       "       [ 3.72369003,  3.30532169],\n",
       "       [ 4.15337467,  1.90415764],\n",
       "       [ 4.84290266,  2.60824823],\n",
       "       [ 5.7469182 ,  1.65122271],\n",
       "       [ 3.30325603,  2.80988598],\n",
       "       [ 3.37481594, -0.31868863],\n",
       "       [ 4.79465294,  2.82427645],\n",
       "       [ 2.17299461,  2.98358083],\n",
       "       [ 4.04927397,  2.45095158],\n",
       "       [ 2.8598361 ,  1.6862278 ],\n",
       "       [ 3.77289248,  3.61293459],\n",
       "       [ 3.68207669,  2.26415348],\n",
       "       [ 3.78914976,  2.10374308],\n",
       "       [ 3.3653357 ,  2.04412651],\n",
       "       [ 5.57165098,  3.7458868 ],\n",
       "       [ 5.91517735,  4.12124252],\n",
       "       [ 3.46607137,  2.32562971],\n",
       "       [ 5.27798557,  1.89941227],\n",
       "       [ 3.80977678,  3.54954886],\n",
       "       [ 4.31009531,  0.58421695],\n",
       "       [ 3.35922217,  0.59427571],\n",
       "       [ 3.03292894,  1.65158856],\n",
       "       [ 5.68587255,  1.17761672],\n",
       "       [ 2.57423115,  2.26218152],\n",
       "       [ 3.48980784,  2.23390818],\n",
       "       [ 4.74932957,  3.22767305],\n",
       "       [ 3.28972006,  3.42701459],\n",
       "       [ 5.24268532,  1.36170292],\n",
       "       [ 5.0310607 ,  2.52782822],\n",
       "       [ 4.33282614,  2.16532755],\n",
       "       [ 4.03166246,  2.28151131],\n",
       "       [ 4.15267086,  2.00761247],\n",
       "       [ 4.80932856,  0.17732811],\n",
       "       [ 4.57589197,  1.44516754],\n",
       "       [ 3.63469172,  2.05048108],\n",
       "       [ 4.54561758,  1.04214859],\n",
       "       [ 4.8005352 ,  0.47386503],\n",
       "       [ 4.54354239,  3.12032032],\n",
       "       [ 5.30806828,  3.04948711],\n",
       "       [ 5.56831264,  1.4602679 ],\n",
       "       [ 2.88482141,  1.79560947],\n",
       "       [ 2.99208212,  2.58489299],\n",
       "       [ 3.44898605,  1.3571018 ],\n",
       "       [ 2.80399227,  2.23535371],\n",
       "       [ 3.33189583,  2.7359643 ],\n",
       "       [ 1.68507648,  1.46542609],\n",
       "       [ 3.65332413,  0.11066163],\n",
       "       [ 3.16505218,  1.10817862],\n",
       "       [ 4.40977144,  3.22375298],\n",
       "       [ 3.03321552,  2.58152318],\n",
       "       [ 3.77981782,  0.76578927],\n",
       "       [ 2.85902357,  1.48494899],\n",
       "       [ 2.08239079,  3.491992  ],\n",
       "       [ 4.57544518,  2.51172209],\n",
       "       [ 5.14495707,  1.59957266],\n",
       "       [ 3.36036682,  2.60659552],\n",
       "       [ 3.47060823,  3.26574278],\n",
       "       [ 2.8342123 ,  2.09392118],\n",
       "       [ 3.16956711,  2.97930765],\n",
       "       [ 3.98412657,  0.58260381],\n",
       "       [ 5.33357668,  1.89599764],\n",
       "       [ 2.1070118 ,  1.18966758],\n",
       "       [ 2.77344561, -0.12446427],\n",
       "       [ 4.09828997,  1.01538277],\n",
       "       [ 3.43638015,  1.06285286],\n",
       "       [ 2.27288151,  0.32872069],\n",
       "       [ 2.41214132,  0.47093427],\n",
       "       [ 4.34425116,  2.48304772],\n",
       "       [ 2.74991155,  3.21962309],\n",
       "       [ 4.83446884,  1.29807949],\n",
       "       [ 3.87798953,  3.23300576],\n",
       "       [ 4.34850359,  1.87721109]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f99858df28>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztnX2MXNWZ5p+3P4xpfyhx2WEsnK4mCEiywDJ229kJa0NmJ9Ywg9jskFhpd4IcYrdoiJMojEbMWloYKY60CloCyWpQT8xmoGonAiaIlUFkJpkYepIspE1svuxYA+62O2QW49WCP+LQdr/7R1W1q6rv9z333nNvPT+p1N3V9557zrnnPuc973nPuaKqIIQQUhy6ss4AIYQQs1DYCSGkYFDYCSGkYFDYCSGkYFDYCSGkYFDYCSGkYFDYCSGkYFDYCSGkYFDYCSGkYPRkcdHly5frwMBAFpcmhJDcsnfv3rdVdYXfcZkI+8DAACYmJrK4NCGE5BYRmQpyHF0xhBBSMCjshBBSMIy4YkRkEsAJAOcAnFXVQRPpEkIICY9JH/snVPXtqCfPzMxgenoaZ86cMZilYrBw4UKsWrUKvb29WWeFEJIDMpk8dWJ6ehpLlizBwMAARCTr7FiDquL48eOYnp7GJZdcknV2CCE5wJSPXQH8g4jsFZGRKAmcOXMGpVKJot6GiKBUKnEkUwSqVWBgAOjqqv2sVrPOESkopiz2a1X1TRH5AIB/FJGDqvpc8wF1wR8BgP7+fsdEKOrOsF4KQLUKjIwAp0/X/p6aqv0NAMPD2eWLFBIjFruqvln/+RaAJwCsczhmTFUHVXVwxQrf+HpCisWOHedFvcHp07XvCTFMbGEXkUUisqTxO4CNAF6Jm24WLF68eO73p59+GpdddhmOHDmSYY5IYXBrR2xfJAFMWOwXAfhnEdkP4AUAT6nqMwbS9SZBf+WPf/xjbN++Hc8884yr26ids2fPGrs+KSBu7Shg+yIkDLGFXVXfUNV/W//8G1XdaSJjnjT8lVNTgOp5f6UBcR8fH8e2bdvw1FNP4dJLLwUAHDt2DDfffDPWrl2LtWvX4qc//SkA4J577sHIyAg2btyIW265BZOTk1i/fj1Wr16N1atX42c/+xkA4De/+Q02bNiAa665BldeeSXGx8dj55PkjJ07gb6+1u/6+mrfE2IaVU39s2bNGm3ntddem/edK+Wyak3SWz/lcvA0HOjp6dH3v//9un///pbvh4aGdHx8XFVVp6am9MMf/rCqqt599926evVqPX36tKqqnjp1Sn/729+qquqhQ4e0Uc57771Xv/71r6uq6tmzZ/Xdd98NnbdQ9UPspFKptVGR2s9KJesckZwBYEIDaKw1ceyhSMhf2dvbi49//OPYtWsX7r///rnvf/SjH+G1116b+/vdd9/FiRMnAAA33XQTLrzwQgC1RVZf+tKXsG/fPnR3d+PQoUMAgLVr1+LWW2/FzMwMPvWpT+Gaa66JlU+SU4aHGQFDUiGfe8Uk5K/s6urCo48+il/84hf4xje+Mff97Owsfv7zn2Pfvn3Yt28ffv3rX2PJkiUAgEWLFs0dd9999+Giiy7C/v37MTExgffeew8AsGHDBjz33HO4+OKL8fnPfx4PP/xwrHwSQogX+RT2BP2VfX192L17N6rVKnbt2gUA2LhxI77zne/MHbNv3z7Hc9955x2sXLkSXV1deOSRR3Du3DkAwNTUFD7wgQ9g27Zt+OIXv4gXX3wxdj47Gi70IcSTfLpiGsPZHTtq7pf+/pqoGxrmLlu2DM888ww2bNiA5cuX44EHHsAdd9yBq6++GmfPnsWGDRvw4IMPzjvv9ttvx80334zHHnsMn/jEJ+as+T179uCb3/wment7sXjxYlrsceBCH0J8kZo/Pl0GBwe1/UUbBw4cwEc+8pHU85IXWD91BgZqYt5OuQxMTqadG0JSRUT2aoDdc/PpiiGdCxf6EOILhZ3kCy70IcQXCjvJF1zoQ4gvFHaSL4aHgbGxmk9dpPZzbIwTp4Q0kc+oGNLZcKEPIZ7QYieEkIJBYW9CRHDnnXfO/X3vvffinnvuyS5DhBASgdwKexKLDy+44AL84Ac/wNtvR34nNyGEZE4uhT2pXXt7enowMjKC++67b97/tmzZgscff3zu78ZLOfbs2YPrrrsOmzZtwuWXX4677roL1WoV69atw1VXXYXXX3997vzbbrsN69evx+WXX47du3cDANavX9+yRcG1116Ll156KV5BCCEdTS6FPcm3jN1xxx2oVqt45513Ap+zf/9+3H///Xj55ZfxyCOP4NChQ3jhhRewdetWfPvb3547bnJyEs8++yyeeuop3HbbbThz5gy2bt2K733vewCAQ4cO4Xe/+x2uvvrq+AUhhHQsuRT2JBcfLl26FLfccgseeOCBwOesXbsWK1euxAUXXIBLL70UGzduBABcddVVmGxa5r5p0yZ0dXXhsssuw4c+9CEcPHgQn/nMZ7B7927MzMzgoYcewpYtW+IXghDS0eRS2JNefPjVr34Vu3btwqlTp+a+6+npwezsLIDay0kaW/ICNd98g66urrm/u7q6Wl6ZJyIt1xER9PX14ZOf/CSefPJJPProo9i8ebOZQhBCOpZcCnvSiw+XLVuGTZs2zW3bCwADAwPYu3cvAODJJ5/EzMxM6HQfe+wxzM7O4vXXX8cbb7yBK664AgCwdetWfPnLX8batWuxbNkyM4UghHQsuRT2NBYf3nnnnS3RMdu2bcOzzz6LdevW4fnnn295wUZQrrjiClx33XW44YYb8OCDD2LhwoUAgDVr1mDp0qX4whe+YCz/hJDOhdv2psSWLVtw44034tOf/vS8/7355pu4/vrrcfDgQXR1Ofe1Ra8fQvJOtZrYKyLm4La9OeHhhx/Gxz72MezcudNV1AkhdpNUCHZUaLHnBNYPIfaS1vtfUrfYRaRbRH4pIrujppFFJ5MHWC+E2I1t738xOfb/CoADUU9euHAhjh8/ThFrQ1Vx/PjxuYlWQoh92Pb+FyPb9orIKgB/CmAngK9FSWPVqlWYnp7GsWPHTGSpUCxcuBCrVq3KOhvhSWM2KU+wPgrLzp2t71gHsn3/i6n92L8F4C8ALImaQG9vLy655BJD2SGZ05hNarT0xmwS0JlixvooNI1baEu/HXvyVERuBPAnqnq7iFwP4M9V9UaH40YAjABAf3//mimnmQZSHNKaTcoLrA9igDQnT68FcJOITAL4PoA/FJFK+0GqOqaqg6o6uGLFCgOXJVZj22xS1hSxPpLYO5sYIbawq+pfquoqVR0A8FkA/6Sqn4udM5JvbJtNypqi1YdtgdsGKUJ/xRUxJBmS3tAnbxStPpLcOztDitJfGRV2Vd3j5F8nHUgaG/rkiaLVRxFdSyhOf2XNylNCSI7I8WSwV9RpV1fNUm9HBKjv2p0p3CuGEJIcOXUt+blaijIVQmEnxaYIM2E2klPXkp+rJaf91TzoiiHFpX1REFB7SnMgQCQZgrhabF4gTFcMySVGDWzDM2E0/vNPEFfL8HBtmmB2tvbTFlEPA4WdWIPxUDODkRuJhsHdfjvQ01MzG3t6an+TRCiKq8UXVU39s2bNGiXFp1JRLZdVRWo/KxXv48tl1Zpstn7K5YgZMJigW1KN5PzK5sroqHOio6MREyR+hG2XNgFgQgNoLIWdJEKlotrX16pVfX3eD5GIs8aJpJiJkHkLlayTonR3OyfY3R2lxKTgBBV2umIypqh+2yju7UihZl4VaDBywy/czdd17+bLOXfO+Xi37wkJQhD1N/2hxV7DoEFpHVGs79D1kWIFOl0q1MjCy5dDi50EBLTY7SdXy5dDDi2iWN9BDey5rHxuCAOnX0UVQ+f/mVAFNufNDU+rPuyEbWOvdkKiEET9TX9osdcw7lNOigiWcVLGtGO6OKkVDKVWgZHK5jWROzp63tfe3c2JU+IKOHlqP8ajQJIiYkaTiD5wzQoOp1qBoctWZL9bp5NimA2FPQfk5ln3CglJOWbMdZSDc4lUoNFnNs9xdsSZlB9iCntOyMWzHmTiL6UeydNiN1yBuel4SXakPOymsBNzBAkJSdEFEkZs43ScuXGVtZMLa6EgpDxRRmEnRqmMjmu5+6gKzmkZh1snK1Oe9Q2qW3Etbne3z2zkPCVNZXRcyzLVep9iDjNsKZuV0GKnsOeVQJEoFpqycZ851/NlqkXdbHHZVCqqfXLK+T5FvDe2lM1a6GOnsOeVQJEoFj7tcUfJQYXSFpeN732KYHLbUjarYVQMhT2PeEaiGG7MJp8RE6JUwWYt4/B8F1RT75DZeoS2yhLMut+n+h8VDNVdNbOB6jc3ay06BAp7gcjax5mW1RZkVBumLoyMkgMUPhOr1qFwZZnytNgrGNI+nAxVH7TY7YLCXhBs8HGmlQc/EYmSj9idYoCLZnKPHCqrgiF31xGgZRwOLdI2tL/2/Pjez6wtoQRJTdgBLATwAoD9AF4F8Fd+51DYg2OLxZTGs+I37M+sLgIUPnUtcamsCja35qO0fe5/gnOR3CpRy2a6TgJ1Mk0HVTB03o1WOlEIfU9T2AXA4vrvvQCeB/DvvM6hsAenk3ycfsJtfV2kqe5Be7kmoYtisUclCUs/UJHrB0VxO+WBTFwxAPoAvAjgY17HUdj9aWiEU0Muqo/TSQxEzu+JleaqUyOZT1JJwlyv3pgq2DzfVZNQFpMYXQXq2OsHpdmJpUmqwg6gG8A+ACcB/Fe/4yns3vgt9CyC5eHG6Oj8B7hRXt94+iwrJgs/UYQRQlqDiiRGV2Es9qhuJ9vJymJ/H4CfALjS4X8jACYATPT39ydfAznGz1LPlaiHVJIgE6jlsrqvgM3KJEtCyXI8CZjE6CqMj50Wu0Fhr10XdwP4c69jaLF7Y70vOSgR3BOBy25bJXn0SJH02bZwlJAkNboKGhVTKW2njz3OB8AKAO+r/34hgHEAN3qdQ2H3xpZImNhEKEjgU2yrJBchroyOR9Nn28oXgaxHVzke8LiSprBfDeCXAF4C8AqA/+J3DoXdm5wba+cRaQ05azzcHlZ14EVKpRPzBSPrSnJQksj6bNuIpE4ksbS0LHmEC5RyThGsDcfhME7WYqu9zvMou+sQv7TdqsnDBpE1zcKJlsgGRwFGH7ZAYSeZUy6dcH6eSyeip1l21ojubn+ByWIkFFnTLAyNci1L91HvnrIwQ9DsobCTSJi0aJMYgXu9pc/GfU8iaVrzIobGS64tsHh9X0voVbgiDEEtgMJOQmPasEpCSL08FH5pZ+XqDaVpToH8bp+k9gJwSavcfdS5zpu3b6aLJVEo7CQ0poU4iRG4n4fCS+usd/VWKsFF3S/jJiu/npbjMn2nF65wUjQxKOwkNHlZY1OpuHsoujGjldFx1/OMu3pNFtBvOJKV36kpreYopxLe0hLemh+dZE1PWTwo7CQ0SVq0Tm7jODroZbn34aSnuBvraEz3FF7WeqkULuMme2mHtFyt994t9J8nCIWdhCap4AVPEY6afn11YTdmnDuj7qPxMh0E0z2hW3oi4Ssp8N4M8zuKef9q2vq38XFdsh8j4on4Q2EnkUjCdeI74Rl2/5CmnsJ1syeci59xP0z7rvy2t4ybVtNuapXeLa0Lx+qWtuNpC2Zq/2/6MsomWx0bGGOw4BR2Yg1+84Fz4XJBzfemnsLVcoxqsYd5CJPwXYW4vu+hLgd4LRxzLVLpREtarmsUXIresaHshgtOYSfWEMhiDyOKTT2Fq6/Xxceu6iGIYR/CiA9tKAPOTZxj6IVrZ4jDgQchYa9vfURSUhguOIXdVjpwPOo70dkcLhfEjdH2sLTsR9N91FfUXQUpykMY8n66ujpK2+en4ZHZOHrh5b4Ks91tmKJ37HYxhgtOYbeRjh2POkXFzEbf8S9GPXoKopfPyFAn7Hr95lFLoywemY2jF65ulPr9SGK7W1rsZgpOYbeRjm3dDjSJc6SXDkcc+XgKop/PqLe3FnYYY7QVaFl+o014ZDZOU6pUaqOEFvFuGjm13I9oxXS+ZlSbJs+jXPrYO4C8jEfTepAqyb8Qob0opZKHIPota23/RMhoIIu90SY81DuuXrTUi9PIKYF2GalZhSmorR0Ao2IKTh4s9pTdRUkvimovyoIFNcPbtXheLhCnT6kUO0+Oy/IbAuBxL4zphc3tMmjeOsTNSWG3Ecsan6MwpPyQJzmIcSuK3yLOSqUWLun65p/2T4j7V6m0jhpKi347L0a8pU2kYYVa1i5bCNpAbO6cDEJhtxVLhouuzzI2B3qQTBUj9PMY4sJec6FuBLaoI4iHa52PjmffJixpl/MI2kDy4uaMCYWdeOL6vHQf9X2QfA28kItsAhuLIS1LtzJ6rdB3rZeuI+7CHlA8UjMqbRXpKAS957TYKezEKzpj1vdB8nyGIgzrA+tQyIe3UnEvp9vz7hm1smhRLPFIYgeCefVms1slKkEaSBHL7QCFnXjiK84eD1KkkEETllMEZQxrZHtGrfT21mZfI4qHyapx1TGHDbtCXcSktZ/2yKFIIxUXKOzEkzgGTqRFPknOhnqIVthT/HzslUXbzk+s+qxyDZR2kDp3EKzAYZMh6r8yOq5lmWqdNI75co6iW9BpQ2EnvkQ1cNzCvUslAxZj2AsHcPOE1ZdKRVt3PmxauBMl5r65nkulkGucXAogmHXW7/aFTgHrv1JR7ZNTzh1alHvXIT7vtKGwk0RpD9ubEwOHLV4TXXFUqfh2UEFdtC3HhNmDvOyd3VhWutMFAff3j5ZORLqg5wjA0Ms5jI3cOpjUhB3ABwH8BMABAK8C+IrfORT2YuAqBm1bvCbppzUx4ndMw9Ae5GEM17miYlbLMuUZYlnBZvdyRxiKeU4ah1yEFbrgJDBpCvtKAKvrvy8BcAjAR73OobAXg8SNsgCqbUI/gnZQYfcgVw1eR6Hj58tlo3OFnhb7ggXhE6ePPREyc8UAeBLAJ72OobAXg1iiGkSVAlzAROeS1B7kAYvgfZzTZKgpgWy6B5XSds+NwSKH7hQ8SiVtMhF2AAMAjgBY6vC/EQATACb6+/uTrwGSOLH8x0FODKC4iVrsDmmE1arYRXXa9dGUqLdlbN7r8sLuk08SJ3VhB7AYwF4Af+Z3LC324hDJKIttxp4/LtaIv575CjbPjwhJdr53Hr4Wu0uGIhvFbhesbZYfr6f0IoYVHyu6qCCkKuwAegH8EMDXghxPYe9wDPs+ImlFW9oVDNVjuGf904jjYnA5d3TUqUpmdRTfcb1GrE7NayOdpHzjMTLsFmKbREdsM2lOngqAhwF8K+g5FHYPbPdLmshfkr6PJPLQnp+owudxbpTsxHJDeZ0cps7DHBsjwx6Rn8YHFTaTprD/ewAK4CUA++qfP/E6h8Lugu2RBD75C/yM21DOqLOucdTU49wo2Yk1cZxYnKhHGjEy7DXACFXunMMFSnnE9thfj/yF1omsRyZR6zqOmhp+1V1go7t0wv1l2XHuQdhM02KPDYU9j9i+Wi+hd3BmgldP5CV4QQrqdr6pjtFn0nd01Ccm3tToKEB7ndfBRFyVTB97DQp7HrFdHV3yVyltd33gbOmTHHESYD+FjfN/E66sAJO+gWLiTbQpn/bquqLXafQQAEbFUNjziQ2+Zy9cYp/bF7Z49UlZe2B8iWORBzk/BfdHoJj4Ro8bN8LHo726ZdXv1YQ2YVt7pbDnlTRbUpRrtZ3jtszeqU+yvd9S1fjusKTdaXEWbbVb7G6LlEonwu0+6dKGgkx4WtkG6tjYXinsxBtDrdbr4W1PynZPk6rGz6TTlpcNM7VBnM47QP4cb62Tj70trajbEofNal6seBvbK4WdeGOo1YZJxva5YVWN3+H5CXvc9KMs2nKLimm7IVG2JQ6b1aCfSB2K4dGuje2Vwk68MdRqw+iUjRaQI3EEwq9eTVSCKQFry0uUbYnDZtWt34vdLpwaokgtRCgivrcqAwc8hZ14Y1Blg7ZvG32WxvGrV5vMwLYbYtpiD3BJz0+oKnGrd5HIDcyzvWbUmCnsBrBtRtwoBhtmmHqysk5NZsqvXm0btjSV3XHr3gS0KqgVH6pKvCZ72hIy0l4j3EcTzYzCHpOOsC4NtPDc11MSBfCqV0sqzC2LWXS8RqrEb6a2Xhhj1R9y5GXquhT2mNhmWGWKR6u0pp6iKlIWPu+oeW0+L8YKHUv6lnl5itWhVCr+8ZV9fZHeguVIyHZj6jmhsMfEJldo5ni0SivqKY5SxS1AmGvHUS8/53QIZbamMzbN6KivuBubIA7Z5kw9JxT2mBS28UfBwB4xc5qGWS13H9UKNpsb67tkolLa7q+jcW90mAqIYyYHCQoPmGcrOmM/6g2mgs1a7j4abJ/8pvPc6sjoBHGIjpoWuyXYOFzNDI9WGaSePBfMmKhUB6UKvNgm7o0OqpJxn2yD+9Zab7TU70msBVMenX0WzzV97BZhZQRHFvi0Sr96chWSxhL3uIricIFQllmcGx1UJeOayQYtdhMiY/rZaEmv+2htc7M41rVHIbN6rhkVQ+wjRqv03ZQqrg/A4SFOYrFN0Gs7qmRcM9mgj72RnEl3fxyr121Eh7j3sICWGYWdWEPiFrvqvIfYWPRDhGu7TpzW3QtlHFbBOS3LlFZGx6NdJ8N9a027ctzS64bzrqHWuIwygMKeMwpoXMwR2sduoDISmyOJkbfK6LjjizHydq9NT766Tx+cM7opWRBsfw4p7DmiEyZqA0fFGKwM4w9pzLxZP2kZENOjIdd6qbeTUFExMcjDc0hhzxFFeeCNYHNlxMxbLsIM/ahUai9XabekF8yY9bFnIKg2N70GQYW9C3mhWgUGBoCurtrPajUfaQfgyJFw3xeaI0dQxRAGcBhdOIcBHEYVQ3ZURswb1d8f7nsr2bEDwzPfwxi2oYxJCGZRxiTGlnwNw8PRkhweBsbGgHIZEKn9HBtD5PSiUqjnMIj6m/6EttiT7NItMBfyYCmkRaW0fb41iJO1/cTDpJPEKv+YN8qCphafpIcdGTq58/AcIk1XDICHALwF4JUgx4cW9iRr3IK7WYgH3hCu/tvSicBphK3PwMcbuFHtujU6mq6OxdbNJJ+XjB+EPDyHaQv7BgCrExP2JK0ESxyfts/Gp4WJ2xFWe0Idb/BGpS0kRq6XZKYtMbJsfg5TFfba9TBAi53ExcTtCNQ5ND3BqS1maiPtpmfsekmpnyVGls0EFfZ8TJ7u3An09bV+19dX+97mtEloTNwO30nKahUYGQGmpgBV9MN5dizpSc20J+uMXW94GJicBGZnaz9NzXLmfHY54xiMVoKof5APfCx2ACMAJgBM9Pf3h++qkhwj2T7+6jDi3g5fb0Gb6Rprs6kY5NZiT4o8OLldSCvrKJQrhpCQeHYOLrtBlnE4f28Osvh6kcipkZVWp0lhJ8QNi0zXtHUsp7ppPWlNDwQVdqkdGw8R+TsA1wNYDuD/ALhbVXe5HT84OKgTExOxr0tIJKpV4NZbgffeO//dggXAQw+lvyqGFIKBgdqUTTvlcm0awhQisldVB/2OMzJ5qqpDqrpSVXtVdZWXqBNiBe0GTUADx6oJMpvo8IqxLgYjiFlv+kNXDMmUiK6YXPios4AVo6rpuLmQpismLHTFkEzp6nK20EVqIXwupDXczh2smNRI1RVDSK6IGC9t5SZRNrhArKyYzobCTjqPiA5R69bPtC20wtRU7e+0xd26iiEUdtJ5RNwn1roJsh07gNOnW787fbr2fZpYVzGEwk5ySbMHYvny2ieUNyLCsvio+4ab9pbMpTf1xvn96puZmkrXLWPLhurkPEFmWE1/GBVD4uAUhGFrQIbpgBHP98cmWRFc2WQFYFQMKSpuQRjN2BKQYTpgxDU9TGISl5i7UDMNX36z26evj1Z5BgSNiqGwk9zhFq3YjE/kYmpEjKwMnx5mMYtucxdqhuGM1sBwxw7Ghgi4JAkSbGFLQIbpgBHX9LrfNHuhZprCFlveRzu1p3BtqyhQ2AuGLRFwSeIUhNGMTQEZpgNGXNMbmUwuMqXeOVQxhBH8DaYwAEUXpjBQuLZVGII44k1/OHmaHBZtXJgozXN5pVLtY+u8nul5R9f0kprgrM/YlnG4I9qWzYCTp52JaZ8uIQCAahVdnxuC00vX2LbSgz72guLnP+ciQJIIw8PoLzvLBduWfVDYc0QQ/zkXAZKkYNvKDxT2HBFkBTkXAZKkYNvKD/Sx5wj6zwnpbOhjLyD0nxNCgkBhzxH0cRIbKPoCuCJAYc8R9HGSrOmEBXBFgMKeMyLsNktCQGvUG1u2gCfe9GSdAUJsoX0Tw4Y1CrADbcC34OUDWuyE1KE16g8n8POBEWEXkT8WkV+JyL+IyF0m0iQkbWiN+sMJ/HwQW9hFpBvAfwdwA4CPAhgSkY/GTZeQtKE16g8n8POBCYt9HYB/UdU3VPU9AN8H8B8NpEtIqtAaDQYn8O3HhLBfDOBo09/T9e9aEJEREZkQkYljx44ZuCyxjpyHlNAaJUXBhLCLw3fzFr6r6piqDqrq4IoVKwxclmSBq3YXJMCZ1igpAiaEfRrAB5v+XgXA5T1dJM94ajdDSgixBhPC/gsAl4nIJSKyAMBnAfwvA+kSy/DUboaUEGINsYVdVc8C+BKAHwI4AOBRVX01brrEPjy1myElhFiDkTh2VX1aVS9X1UtVlTEEBcVTuxlSQog1cOUpCYyndjOkhBBr4F4xJDANjd6xo+Z+6e+vifqcdg8PU8gJsQBa7CQUtoYD5jyEnhCj0GInuYe7MhLSCi12knsYQk9IKxR2knsYQk9IKxR2knsYQk9IKxR2knsYQk9IKxR2knsYQk9IK4yKIYWAIfSEnIcWOyGEFAwKOyGEFAwKOyGEFAwKOyGEFAwKOyGEFAwKOyGEFAwKOyGEFAwKOyGEFAwKOyGEFAwKOyGEFAwKOyGEFAwKOyGEFIxYwi4inxGRV0VkVkQGTWWKEEJIdOJa7K8A+DMAzxnICyGEEAPE2rZXVQ8AgIiYyQ0hhJDY0MdOCCEFw9diF5EfAfg9h3/tUNUng15IREYAjABAP19GSQghieEr7Kr6RyYupKpjAMYAYHBwUE2kSQghZD50xRCqpmKpAAAEGUlEQVRCSMGIG+74n0RkGsAfAHhKRH5oJluEEEKiEjcq5gkATxjKCyGEEAPQFUMIIQWDwk4IIQWDwk4IIQWDwk7yS7UKDAwAXV21n9Vq1jkixApiTZ4SkhnVKjAyApw+Xft7aqr2NwAMD2eXL0IsgBY7ySc7dpwX9QanT9e+J6TDobCTfHLkSLjvCekgKOwkn7jtN8R9iAihsJOcsnMn0NfX+l1fX+17QjocCjvJJ8PDwNgYUC4DIrWfY2OcOCUEjIoheWZ4mEJOiAO02AkhpGBQ2AkhpGBQ2AkhpGBQ2AkhpGBQ2AkhpGCIavqvHxWREwB+lfqF7WE5gLezzkRGdHLZgc4uP8sen7KqrvA7KKtwx1+p6mBG184cEZno1PJ3ctmBzi4/y55e2emKIYSQgkFhJ4SQgpGVsI9ldF1b6OTyd3LZgc4uP8ueEplMnhJCCEkOumIIIaRgpCrsIvKQiLwlIq+keV0bEJEPishPROSAiLwqIl/JOk9pIiILReQFEdlfL/9fZZ2ntBGRbhH5pYjszjovaSMikyLysojsE5GJrPOTJiLyPhF5XEQO1p//P0j8mmm6YkRkA4CTAB5W1StTu7AFiMhKACtV9UURWQJgL4BPqeprGWctFUREACxS1ZMi0gvgnwF8RVX/d8ZZSw0R+RqAQQBLVfXGrPOTJiIyCWBQVTsujl1E/hbAuKp+V0QWAOhT1f+X5DVTtdhV9TkA/zfNa9qCqv5GVV+s/34CwAEAF2ebq/TQGifrf/bWPx0zwSMiqwD8KYDvZp0Xkh4ishTABgC7AEBV30ta1AH62DNBRAYA/D6A57PNSbrUXRH7ALwF4B9VtZPK/y0AfwFgNuuMZIQC+AcR2SsiI1lnJkU+BOAYgP9Rd8N9V0QWJX1RCnvKiMhiAH8P4Kuq+m7W+UkTVT2nqtcAWAVgnYh0hDtORG4E8Jaq7s06LxlyraquBnADgDvqbtlOoAfAagB/raq/D+AUgLuSviiFPUXqvuW/B1BV1R9knZ+sqA9F9wD444yzkhbXArip7mf+PoA/FJFKtllKF1V9s/7zLQBPAFiXbY5SYxrAdNPo9HHUhD5RKOwpUZ883AXggKr+t6zzkzYiskJE3lf//UIAfwTgYLa5SgdV/UtVXaWqAwA+C+CfVPVzGWcrNURkUT1gAHU3xEYAHREZp6r/CuCoiFxR/+o/AEg8YCLVTcBE5O8AXA9guYhMA7hbVXelmYcMuRbA5wG8XPczA8B/VtWnM8xTmqwE8Lci0o2aQfGoqnZc2F+HchGAJ2q2DXoA/E9VfSbbLKXKdgDVekTMGwC+kPQFufKUEEIKBl0xhBBSMCjshBBSMCjshBBSMCjshBBSMCjshBBSMCjshBBSMCjshBBSMCjshBBSMP4/lkaU94qku3QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np_sampling[:,0],np_sampling[:,1],'ro')\n",
    "plt.plot(keras_sampling[:,0],keras_sampling[:,1],'bo')\n",
    "plt.legend(['Keras', 'Numpy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 恭喜你，完成所有建立 Variational Autoencoder 所需的重要技巧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variational Autoencoder (VAE) 是一個重要的非監督式學習模型，具體應用的場合為特徵抽取/資料壓縮及還原，為影像處理中常見的模型之一。\n",
    "\n",
    "在建立 VAE中，需要三個重要技巧:\n",
    "* 分歧-合併\n",
    "* 自定義函數 (抽樣函數)\n",
    "* 自定義損失函數\n",
    "\n",
    "雖然不知道之後課程會不會用到，但多學點總是好的 : )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
