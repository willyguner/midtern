{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND=tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\w8462\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.reshape(60000,784)\n",
    "x_test=x_test.reshape(10000,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np_utils.to_categorical(y_train,10)\n",
    "y_test=np_utils.to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 規一化\n",
    "\n",
    "首先測試規一化後的資料會不會使準確力提高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_std=x_train/x_train.max()\n",
    "x_test_std=x_test/x_test.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(4,input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',optimizer=SGD(lr=0.087),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 4)                 3140      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 3,180\n",
      "Trainable params: 3,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.0906 - acc: 0.0974 - val_loss: 0.0905 - val_acc: 0.0982\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0904 - acc: 0.0974 - val_loss: 0.0903 - val_acc: 0.0982\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0903 - acc: 0.0974 - val_loss: 0.0902 - val_acc: 0.0982\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0902 - acc: 0.0974 - val_loss: 0.0901 - val_acc: 0.0982\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0901 - acc: 0.0974 - val_loss: 0.0901 - val_acc: 0.0982\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0901 - acc: 0.0977 - val_loss: 0.0900 - val_acc: 0.0997\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0900 - acc: 0.1072 - val_loss: 0.0900 - val_acc: 0.1075\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0900 - acc: 0.0918 - val_loss: 0.0900 - val_acc: 0.0768\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0900 - acc: 0.0789 - val_loss: 0.0899 - val_acc: 0.0931\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0899 - acc: 0.0994 - val_loss: 0.0899 - val_acc: 0.1123\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0899 - acc: 0.1151 - val_loss: 0.0899 - val_acc: 0.1207\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0899 - acc: 0.1196 - val_loss: 0.0899 - val_acc: 0.1186\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0899 - acc: 0.1175 - val_loss: 0.0899 - val_acc: 0.1165\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0899 - acc: 0.1155 - val_loss: 0.0898 - val_acc: 0.1156\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0898 - acc: 0.1152 - val_loss: 0.0898 - val_acc: 0.1155\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0898 - acc: 0.1147 - val_loss: 0.0898 - val_acc: 0.1160\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0898 - acc: 0.1159 - val_loss: 0.0898 - val_acc: 0.1170\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0898 - acc: 0.1160 - val_loss: 0.0898 - val_acc: 0.1181\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0898 - acc: 0.1197 - val_loss: 0.0897 - val_acc: 0.1211\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0897 - acc: 0.1217 - val_loss: 0.0897 - val_acc: 0.1254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x208960deef0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_std,y_train,batch_size=100,epochs=20,verbose=1,validation_data=(x_test_std,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小結\n",
    "\n",
    "看起來單純的規一化後並沒有比較好，似乎還變差了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 改變Learning Rate\n",
    "\n",
    "接著試著改改看Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=Sequential()\n",
    "model2.add(Dense(4,input_dim=784))\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.add(Dense(2))\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.add(Dense(10))\n",
    "model2.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='mse',optimizer=SGD(lr=1.8),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0899 - acc: 0.1746 - val_loss: 0.0894 - val_acc: 0.1814\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0888 - acc: 0.1721 - val_loss: 0.0877 - val_acc: 0.1111\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0855 - acc: 0.2193 - val_loss: 0.0831 - val_acc: 0.2529\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0817 - acc: 0.2730 - val_loss: 0.0802 - val_acc: 0.2996\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0787 - acc: 0.3269 - val_loss: 0.0769 - val_acc: 0.3725\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0753 - acc: 0.3832 - val_loss: 0.0735 - val_acc: 0.3933\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0718 - acc: 0.3910 - val_loss: 0.0702 - val_acc: 0.3936\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0689 - acc: 0.3924 - val_loss: 0.0678 - val_acc: 0.3943\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0670 - acc: 0.3954 - val_loss: 0.0662 - val_acc: 0.4010\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0656 - acc: 0.4069 - val_loss: 0.0650 - val_acc: 0.4229\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0645 - acc: 0.4360 - val_loss: 0.0639 - val_acc: 0.4490\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0634 - acc: 0.4576 - val_loss: 0.0628 - val_acc: 0.4618\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0622 - acc: 0.4699 - val_loss: 0.0615 - val_acc: 0.4726\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0607 - acc: 0.4844 - val_loss: 0.0597 - val_acc: 0.4869\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0587 - acc: 0.5187 - val_loss: 0.0575 - val_acc: 0.5448\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0566 - acc: 0.5537 - val_loss: 0.0555 - val_acc: 0.5563\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0548 - acc: 0.5614 - val_loss: 0.0539 - val_acc: 0.5624\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0534 - acc: 0.5778 - val_loss: 0.0526 - val_acc: 0.5894\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0522 - acc: 0.5903 - val_loss: 0.0516 - val_acc: 0.5817\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0513 - acc: 0.5909 - val_loss: 0.0508 - val_acc: 0.6020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x208960def98>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train_std,y_train,batch_size=100,epochs=20,verbose=1,validation_data=(x_test_std,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小結\n",
    "\n",
    "重複調整數次，發現當數值小於原本的0.087時，其正確率會降得更低。  \n",
    "相反的提高LR則會使正確率提高，不過大概到1.7、1.8就是極限了，再高就會開始下降。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 調整層數及神經元個數\n",
    "\n",
    "接著調整層數及神經元個數，理論上多一點應該會讓精準率提高才對吧!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3=Sequential()\n",
    "model3.add(Dense(100,input_dim=784))\n",
    "model3.add(Activation('sigmoid'))\n",
    "model3.add(Dense(100))\n",
    "model3.add(Activation('sigmoid'))\n",
    "#model3.add(Dense(100))\n",
    "#model3.add(Activation('sigmoid'))\n",
    "model3.add(Dense(10))\n",
    "model3.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss='mse',optimizer=SGD(lr=25),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1794 - acc: 0.0985 - val_loss: 0.1808 - val_acc: 0.0958\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1803 - acc: 0.0986 - val_loss: 0.1808 - val_acc: 0.0958\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1803 - acc: 0.0986 - val_loss: 0.1808 - val_acc: 0.0958\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1803 - acc: 0.0986 - val_loss: 0.1808 - val_acc: 0.0958\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1803 - acc: 0.0986 - val_loss: 0.1808 - val_acc: 0.0958\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1803 - acc: 0.0986 - val_loss: 0.1808 - val_acc: 0.0958\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1803 - acc: 0.0986 - val_loss: 0.1808 - val_acc: 0.0958\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1803 - acc: 0.0986 - val_loss: 0.1808 - val_acc: 0.0958\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1803 - acc: 0.0986 - val_loss: 0.1808 - val_acc: 0.0958\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1803 - acc: 0.0986 - val_loss: 0.1808 - val_acc: 0.0958\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1803 - acc: 0.0986 - val_loss: 0.1808 - val_acc: 0.0958\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1803 - acc: 0.0986 - val_loss: 0.1808 - val_acc: 0.0958\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.1092 - acc: 0.3303 - val_loss: 0.0186 - val_acc: 0.8764\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0139 - acc: 0.9080 - val_loss: 0.0098 - val_acc: 0.9374\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0092 - acc: 0.9404 - val_loss: 0.0076 - val_acc: 0.9501\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0070 - acc: 0.9551 - val_loss: 0.0064 - val_acc: 0.9585\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0057 - acc: 0.9634 - val_loss: 0.0058 - val_acc: 0.9625\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0048 - acc: 0.9692 - val_loss: 0.0053 - val_acc: 0.9642\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0042 - acc: 0.9740 - val_loss: 0.0055 - val_acc: 0.9642\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0037 - acc: 0.9774 - val_loss: 0.0046 - val_acc: 0.9694\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0032 - acc: 0.9800 - val_loss: 0.0044 - val_acc: 0.9717\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0029 - acc: 0.9821 - val_loss: 0.0044 - val_acc: 0.9705\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0026 - acc: 0.9841 - val_loss: 0.0046 - val_acc: 0.9701\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0023 - acc: 0.9858 - val_loss: 0.0039 - val_acc: 0.9743\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0021 - acc: 0.9872 - val_loss: 0.0039 - val_acc: 0.9743\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0019 - acc: 0.9887 - val_loss: 0.0037 - val_acc: 0.9748\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0018 - acc: 0.9895 - val_loss: 0.0040 - val_acc: 0.9741\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0017 - acc: 0.9903 - val_loss: 0.0041 - val_acc: 0.9729\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0015 - acc: 0.9912 - val_loss: 0.0039 - val_acc: 0.9735\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0014 - acc: 0.9920 - val_loss: 0.0036 - val_acc: 0.9765\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0012 - acc: 0.9933 - val_loss: 0.0038 - val_acc: 0.9761\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0011 - acc: 0.9938 - val_loss: 0.0033 - val_acc: 0.9782\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0010 - acc: 0.9944 - val_loss: 0.0038 - val_acc: 0.9752\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 9.4061e-04 - acc: 0.9951 - val_loss: 0.0035 - val_acc: 0.9770\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 8.5626e-04 - acc: 0.9956 - val_loss: 0.0035 - val_acc: 0.9771\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 8.2186e-04 - acc: 0.9956 - val_loss: 0.0036 - val_acc: 0.9765\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 7.2058e-04 - acc: 0.9962 - val_loss: 0.0033 - val_acc: 0.9782\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 6.6268e-04 - acc: 0.9965 - val_loss: 0.0035 - val_acc: 0.9764\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 6.5479e-04 - acc: 0.9965 - val_loss: 0.0035 - val_acc: 0.9771\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 5.8075e-04 - acc: 0.9970 - val_loss: 0.0034 - val_acc: 0.9782\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 5.4962e-04 - acc: 0.9972 - val_loss: 0.0033 - val_acc: 0.9785\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 5.0971e-04 - acc: 0.9973 - val_loss: 0.0033 - val_acc: 0.9791\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 4.8590e-04 - acc: 0.9974 - val_loss: 0.0033 - val_acc: 0.9794\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 4.7694e-04 - acc: 0.9974 - val_loss: 0.0033 - val_acc: 0.9794\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 4.6203e-04 - acc: 0.9975 - val_loss: 0.0034 - val_acc: 0.9784\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 4.4656e-04 - acc: 0.9976 - val_loss: 0.0033 - val_acc: 0.9798\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 4.3569e-04 - acc: 0.9976 - val_loss: 0.0034 - val_acc: 0.9792\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 4.2005e-04 - acc: 0.9977 - val_loss: 0.0033 - val_acc: 0.9787\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 4.0032e-04 - acc: 0.9979 - val_loss: 0.0032 - val_acc: 0.9792\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 3.8601e-04 - acc: 0.9979 - val_loss: 0.0033 - val_acc: 0.9788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x209939e4908>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x_train_std,y_train,batch_size=100,epochs=50,verbose=1,validation_data=(x_test_std,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小結\n",
    "\n",
    "這邊重複調整許多次，但好像看不太出來明確的因果關係，但可以確定的是神經元數提高，精確率會提高(不過也不知道實際要提高到哪)。  \n",
    "還有調整至三層似乎跟兩層出來的結果差不多，甚至有的時候還會比較低一點。  \n",
    "另外就是，原本在前面只調LR時大概是1.7、1.8時準確率會最高，但是在神經元個數調整後反而是高達25左右會最高，此時準確率也達到9成9了。  \n",
    "不確定是不是因為我把神經元個數調高因此LR也跟著需要提高(？\n",
    "\n",
    "當然我也測試過各種其他組合，像是神經元個數逐層上升(下降)，就不詳述了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 改變Activation Function\n",
    "\n",
    "根據上課助教所講的各式Activation Function，分別測試看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4=Sequential()\n",
    "model4.add(Dense(100,input_dim=784))\n",
    "model4.add(Activation('tanh'))\n",
    "model4.add(Dense(100))\n",
    "model4.add(Activation('tanh'))\n",
    "model4.add(Dense(10))\n",
    "model4.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(loss='mse',optimizer=SGD(lr=11),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0743 - acc: 0.5972 - val_loss: 0.0098 - val_acc: 0.9357\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0081 - acc: 0.9468 - val_loss: 0.0070 - val_acc: 0.9531\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0056 - acc: 0.9629 - val_loss: 0.0057 - val_acc: 0.9633\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0044 - acc: 0.9713 - val_loss: 0.0053 - val_acc: 0.9666\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0037 - acc: 0.9769 - val_loss: 0.0049 - val_acc: 0.9688\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0030 - acc: 0.9813 - val_loss: 0.0043 - val_acc: 0.9710\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0026 - acc: 0.9834 - val_loss: 0.0039 - val_acc: 0.9745\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0023 - acc: 0.9860 - val_loss: 0.0041 - val_acc: 0.9729\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0020 - acc: 0.9882 - val_loss: 0.0041 - val_acc: 0.9736\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0017 - acc: 0.9903 - val_loss: 0.0039 - val_acc: 0.9742\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0015 - acc: 0.9916 - val_loss: 0.0037 - val_acc: 0.9744\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0013 - acc: 0.9928 - val_loss: 0.0037 - val_acc: 0.9753\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0012 - acc: 0.9935 - val_loss: 0.0037 - val_acc: 0.9759\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0010 - acc: 0.9943 - val_loss: 0.0035 - val_acc: 0.9773\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 9.3351e-04 - acc: 0.9948 - val_loss: 0.0036 - val_acc: 0.9762\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 7.9767e-04 - acc: 0.9958 - val_loss: 0.0037 - val_acc: 0.9766\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 7.5575e-04 - acc: 0.9959 - val_loss: 0.0037 - val_acc: 0.9756\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 6.5952e-04 - acc: 0.9966 - val_loss: 0.0035 - val_acc: 0.9780\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 5.3535e-04 - acc: 0.9972 - val_loss: 0.0035 - val_acc: 0.9773\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 5.0376e-04 - acc: 0.9974 - val_loss: 0.0034 - val_acc: 0.9778\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 4.5874e-04 - acc: 0.9976 - val_loss: 0.0035 - val_acc: 0.9767\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 4.0746e-04 - acc: 0.9978 - val_loss: 0.0034 - val_acc: 0.9780\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 3.7887e-04 - acc: 0.9980 - val_loss: 0.0034 - val_acc: 0.9767\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 3.3947e-04 - acc: 0.9982 - val_loss: 0.0033 - val_acc: 0.9781\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 3.2113e-04 - acc: 0.9983 - val_loss: 0.0033 - val_acc: 0.9782\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 3.0655e-04 - acc: 0.9983 - val_loss: 0.0034 - val_acc: 0.9774\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.9282e-04 - acc: 0.9984 - val_loss: 0.0034 - val_acc: 0.9780\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.8760e-04 - acc: 0.9984 - val_loss: 0.0034 - val_acc: 0.9776\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.7671e-04 - acc: 0.9985 - val_loss: 0.0033 - val_acc: 0.9787\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.7460e-04 - acc: 0.9985 - val_loss: 0.0034 - val_acc: 0.9781\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.6958e-04 - acc: 0.9985 - val_loss: 0.0034 - val_acc: 0.9783\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.7174e-04 - acc: 0.9985 - val_loss: 0.0034 - val_acc: 0.9775\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.5785e-04 - acc: 0.9986 - val_loss: 0.0034 - val_acc: 0.9782\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.5201e-04 - acc: 0.9986 - val_loss: 0.0034 - val_acc: 0.9784\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.4987e-04 - acc: 0.9986 - val_loss: 0.0033 - val_acc: 0.9784\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.4653e-04 - acc: 0.9986 - val_loss: 0.0034 - val_acc: 0.9780\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.4175e-04 - acc: 0.9986 - val_loss: 0.0033 - val_acc: 0.9780\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.3556e-04 - acc: 0.9987 - val_loss: 0.0033 - val_acc: 0.9781\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.3435e-04 - acc: 0.9987 - val_loss: 0.0034 - val_acc: 0.9779\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.2802e-04 - acc: 0.9987 - val_loss: 0.0033 - val_acc: 0.9786\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.3148e-04 - acc: 0.9987 - val_loss: 0.0033 - val_acc: 0.9782\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.1797e-04 - acc: 0.9988 - val_loss: 0.0033 - val_acc: 0.9784\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.1556e-04 - acc: 0.9988 - val_loss: 0.0033 - val_acc: 0.9781\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.1586e-04 - acc: 0.9988 - val_loss: 0.0034 - val_acc: 0.9781\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.1291e-04 - acc: 0.9988 - val_loss: 0.0034 - val_acc: 0.9784\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.1188e-04 - acc: 0.9988 - val_loss: 0.0033 - val_acc: 0.9788\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2.0319e-04 - acc: 0.9989 - val_loss: 0.0033 - val_acc: 0.9785\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 1.9678e-04 - acc: 0.9989 - val_loss: 0.0034 - val_acc: 0.9778\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 1.8810e-04 - acc: 0.9989 - val_loss: 0.0034 - val_acc: 0.9788\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 1.8322e-04 - acc: 0.9990 - val_loss: 0.0033 - val_acc: 0.9791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2099efea518>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(x_train_std,y_train,batch_size=100,epochs=50,verbose=1,validation_data=(x_test_std,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小結\n",
    "\n",
    "使用relu跟tanh都可以達到9成9，其中tanh更達到99.7%的準確率。而selu則會有準確率先升後降的情況發生，其最高也只有9成2的準確率。  \n",
    "還有改變Activation Function時，LR也須跟著改變才會有最好的訓練結果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 改變optimizer\n",
    "\n",
    "同樣根據上課助教所講的各式optimizer，分別測試看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5=Sequential()\n",
    "model5.add(Dense(100,input_dim=784))\n",
    "model5.add(Activation('tanh'))\n",
    "model5.add(Dense(100))\n",
    "model5.add(Activation('tanh'))\n",
    "model5.add(Dense(10))\n",
    "model5.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.compile(loss='mse',optimizer=Adadelta(lr=2),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0190 - acc: 0.8796 - val_loss: 0.0112 - val_acc: 0.9283\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0108 - acc: 0.9308 - val_loss: 0.0093 - val_acc: 0.9392\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0087 - acc: 0.9448 - val_loss: 0.0082 - val_acc: 0.9485\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0073 - acc: 0.9540 - val_loss: 0.0068 - val_acc: 0.9571\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0063 - acc: 0.9605 - val_loss: 0.0062 - val_acc: 0.9606\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0055 - acc: 0.9658 - val_loss: 0.0059 - val_acc: 0.9621\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0050 - acc: 0.9699 - val_loss: 0.0052 - val_acc: 0.9676\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0044 - acc: 0.9729 - val_loss: 0.0050 - val_acc: 0.9687\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0041 - acc: 0.9752 - val_loss: 0.0046 - val_acc: 0.9698\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0037 - acc: 0.9780 - val_loss: 0.0046 - val_acc: 0.9704\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0034 - acc: 0.9799 - val_loss: 0.0044 - val_acc: 0.9719\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0031 - acc: 0.9821 - val_loss: 0.0043 - val_acc: 0.9725\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0029 - acc: 0.9839 - val_loss: 0.0040 - val_acc: 0.9739\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0027 - acc: 0.9848 - val_loss: 0.0040 - val_acc: 0.9742\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0025 - acc: 0.9864 - val_loss: 0.0039 - val_acc: 0.9747\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0023 - acc: 0.9873 - val_loss: 0.0040 - val_acc: 0.9748\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0022 - acc: 0.9879 - val_loss: 0.0037 - val_acc: 0.9753\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0020 - acc: 0.9890 - val_loss: 0.0037 - val_acc: 0.9745\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0019 - acc: 0.9899 - val_loss: 0.0036 - val_acc: 0.9770\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0018 - acc: 0.9904 - val_loss: 0.0036 - val_acc: 0.9764\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0017 - acc: 0.9910 - val_loss: 0.0037 - val_acc: 0.9771\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0016 - acc: 0.9918 - val_loss: 0.0035 - val_acc: 0.9768\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0015 - acc: 0.9920 - val_loss: 0.0035 - val_acc: 0.9774\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0014 - acc: 0.9929 - val_loss: 0.0036 - val_acc: 0.9763\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0013 - acc: 0.9933 - val_loss: 0.0035 - val_acc: 0.9770\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0013 - acc: 0.9936 - val_loss: 0.0034 - val_acc: 0.9775\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0012 - acc: 0.9942 - val_loss: 0.0034 - val_acc: 0.9776\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0011 - acc: 0.9944 - val_loss: 0.0034 - val_acc: 0.9772\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0011 - acc: 0.9948 - val_loss: 0.0035 - val_acc: 0.9765\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0010 - acc: 0.9949 - val_loss: 0.0034 - val_acc: 0.9775\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 9.7474e-04 - acc: 0.9953 - val_loss: 0.0033 - val_acc: 0.9773\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 9.1943e-04 - acc: 0.9955 - val_loss: 0.0034 - val_acc: 0.9775\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 8.8570e-04 - acc: 0.9957 - val_loss: 0.0033 - val_acc: 0.9771\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 8.4640e-04 - acc: 0.9959 - val_loss: 0.0033 - val_acc: 0.9779\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 8.0502e-04 - acc: 0.9962 - val_loss: 0.0034 - val_acc: 0.9774\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 7.6941e-04 - acc: 0.9963 - val_loss: 0.0033 - val_acc: 0.9770\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 7.4170e-04 - acc: 0.9964 - val_loss: 0.0033 - val_acc: 0.9777\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 7.1409e-04 - acc: 0.9965 - val_loss: 0.0034 - val_acc: 0.9779\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 6.8671e-04 - acc: 0.9967 - val_loss: 0.0033 - val_acc: 0.9769\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 6.6866e-04 - acc: 0.9967 - val_loss: 0.0033 - val_acc: 0.9779\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 6.4734e-04 - acc: 0.9968 - val_loss: 0.0033 - val_acc: 0.9775\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 6.2965e-04 - acc: 0.9969 - val_loss: 0.0033 - val_acc: 0.9773\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 6.1313e-04 - acc: 0.9970 - val_loss: 0.0033 - val_acc: 0.9778\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 5.9270e-04 - acc: 0.9971 - val_loss: 0.0034 - val_acc: 0.9775\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 5.7513e-04 - acc: 0.9972 - val_loss: 0.0033 - val_acc: 0.9781\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 5.6384e-04 - acc: 0.9971 - val_loss: 0.0033 - val_acc: 0.9784\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 5.4793e-04 - acc: 0.9972 - val_loss: 0.0034 - val_acc: 0.9770\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 5.3223e-04 - acc: 0.9973 - val_loss: 0.0033 - val_acc: 0.9775\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 5.1793e-04 - acc: 0.9974 - val_loss: 0.0033 - val_acc: 0.9774\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 5.0951e-04 - acc: 0.9974 - val_loss: 0.0034 - val_acc: 0.9779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2099f20e898>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(x_train_std,y_train,batch_size=100,epochs=50,verbose=1,validation_data=(x_test_std,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小結\n",
    "\n",
    "分別使用Adam以及Adadelta，基本上都能達到9成8以上的準確率，只不過LR要隨著你使用的optimizer去更改才能有最好的訓練結果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 將測試資料輸入我們測試的這些模型，看分數能得到多少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 30us/step\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "10000/10000 [==============================] - 0s 29us/step\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(x_test,y_test)\n",
    "score2=model2.evaluate(x_test,y_test)\n",
    "score3=model3.evaluate(x_test,y_test)\n",
    "score4=model4.evaluate(x_test,y_test)\n",
    "score5=model5.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modle正確率 0.1792\n",
      "modle2正確率 0.5434\n",
      "modle3正確率 0.9544\n",
      "modle4正確率 0.9651\n",
      "modle5正確率 0.9498\n"
     ]
    }
   ],
   "source": [
    "print('modle正確率',score[1])\n",
    "print('modle2正確率',score2[1])\n",
    "print('modle3正確率',score3[1])\n",
    "print('modle4正確率',score4[1])\n",
    "print('modle5正確率',score5[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小結\n",
    "\n",
    "儘管model3、4、5訓練出來的模型差不多，其測試成績最終仍有些微差距。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 結論\n",
    "\n",
    "1.基本上模型的訓練可以有很多種方法都能達到幾乎百分之百的準確率，不過訓練速度又是另外需要討論的。\n",
    "\n",
    "2.牽一髮而動全身。只要動到一個地方，其他地方就有可能要跟著調整，尤其是LR在這次作業中幾乎都要不斷的修正，才能有最好的訓練結果。\n",
    "\n",
    "3.這次作業仍有一些地方沒有測試，像是改變Loss Function。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
